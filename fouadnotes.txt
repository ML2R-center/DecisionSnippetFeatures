read data -> one for each dataset
1) size comparison #nodes
2) inferance comparison #i

features and logs only to understand whats happening
start with 5 then 10... until i get stuck
features: where do the found subtrees are located

fouads version of notebook 3?
don't need all embedings

after 3:
Classificaton (you could ommit if( freq <4)
    results path acuricy -> will be used almost everything
    one code for every learning algorithm

Learning Algorithm
    compare the different accuracies
    input: accuracy

Size comparison:
    count nodes

inference comparison, compare number of ifs from route to bottom
-> uses feature generating tree, x, output variables in function, different then pascals code

ForestSampling
    subtrees sample from *all* subtrees
->DSF_Samples (similar to classification notebook) [check nullhypothesis]

DSF_RF
    use descision snippet features as a random Forest
    results. details -> majority class or probability(quotient)
    _p means probability
    
Learning Algo:
    output will be image and ...

Draw (contains some code for drawing)


classification: adult bank letter magic mnist satlog sensorlese-drive spambase
(regression : wine-quality)


