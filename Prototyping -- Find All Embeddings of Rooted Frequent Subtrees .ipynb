{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the Embeddings of the Frequent Patterns\n",
    "\n",
    "It should be easy (and fast enough) to find all embeddings of a few frequent patterns in the random forest database.\n",
    "\n",
    "To do this, we need to \n",
    "\n",
    "- [x] select the right patterns (e.g. those of size six)\n",
    "- [x] read my canonical string format in python / transform it to json\n",
    "- [x] read the json database format in python\n",
    "- [ ] write a small script that traverses the random forests and finds all embeddings and outputs them somehow\n",
    "\n",
    "## Select the Right Patterns (e.g. those of size six)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['61 ( leftChild 63 ( leftChild leaf ) ) ( rightChild leaf ) \\n', '63 ( leftChild 0 ( leftChild leaf ) ( rightChild leaf ) ) \\n', '63 ( leftChild 0 ( leftChild leaf ) ) ( rightChild leaf ) \\n', '63 ( rightChild 9 ( leftChild leaf ) ( rightChild leaf ) ) \\n', '63 ( rightChild 0 ( leftChild leaf ) ( rightChild leaf ) ) \\n', '26 ( rightChild 9 ( leftChild leaf ) ( rightChild leaf ) ) \\n', '0 ( leftChild 9 ( leftChild leaf ) ( rightChild leaf ) ) \\n', '0 ( leftChild 9 ( leftChild leaf ) ) ( rightChild leaf ) \\n', '0 ( rightChild 0 ( leftChild leaf ) ( rightChild leaf ) ) \\n', '0 ( rightChild 63 ( leftChild leaf ) ( rightChild leaf ) ) \\n', '0 ( rightChild 9 ( leftChild leaf ) ( rightChild leaf ) ) \\n', '9 ( leftChild leaf ) ( rightChild 0 ( rightChild leaf ) ) \\n', '9 ( rightChild 0 ( leftChild leaf ) ( rightChild leaf ) ) \\n', '9 ( rightChild 9 ( leftChild leaf ) ( rightChild leaf ) ) \\n']\n"
     ]
    }
   ],
   "source": [
    "# pattern size in number of vertices\n",
    "patternSize = 4\n",
    "# here, we count the number of edges in the pattern\n",
    "patternSize = patternSize - 1 \n",
    "\n",
    "filename = 'forests/rootedFrequentTrees/adult/WithLeafEdges/RF_10_t10.patterns'\n",
    "f = open(filename)\n",
    "\n",
    "# gives us the patterns of the selected size\n",
    "frequentPatterns = filter(lambda line: line.count('(') == patternSize, f)\n",
    "\n",
    "# gives us only the canonical strings of the patterns\n",
    "cStrings = map(lambda fp: fp.split('\\t')[2], frequentPatterns)\n",
    "\n",
    "cStringList = list(cStrings)\n",
    "print(cStringList)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transform my canonical string format to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"id\":0,\"feature\":61,\"leftChild\":{\"id\":1,\"feature\":63,\"leftChild\":{\"id\":2,\"prediction\":[]}},\"rightChild\":{\"id\":3,\"prediction\":[]}}'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '61 ( leftChild 63 ( leftChild leaf ) ) ( rightChild leaf ) \\n'\n",
    "\n",
    "\n",
    "\n",
    "def cString2json(cString):\n",
    "    '''Pascals canonical string format and the json format used in Dortmund are \n",
    "    basically identical (up to ordering, symbols, and general feeling of course ;) ).\n",
    "    This is a converter that transforms a single tree from cString format to json format \n",
    "    (entirely by string maipulation).'''\n",
    "    \n",
    "    intermediate = cString.replace('( leftChild', ',\"leftChild\":{').replace('( rightChild', ',\"rightChild\":{').replace(')', '}').replace('leaf', '-1 \"prediction\":[]')\n",
    "    tokens = intermediate.split(' ')\n",
    "    \n",
    "    json = ''\n",
    "    i = 0\n",
    "    for t in tokens:\n",
    "        try:\n",
    "            feature = int(t)\n",
    "            if feature != -1:\n",
    "                s = '\"id\":' + str(i) + ',\"feature\":' + t\n",
    "            else:\n",
    "                s = '\"id\":' + str(i) + ','\n",
    "            json += s\n",
    "            i += 1\n",
    "        except ValueError:\n",
    "            json += t\n",
    "            \n",
    "            \n",
    "    return ('{' + json.rstrip() + '}')\n",
    "    \n",
    "cString2json(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"id\":0,\"feature\":61,\"leftChild\":{\"id\":1,\"feature\":63,\"leftChild\":{\"id\":2,\"prediction\":[]}},\"rightChild\":{\"id\":3,\"prediction\":[]}},\n",
      "{\"id\":0,\"feature\":63,\"leftChild\":{\"id\":1,\"feature\":0,\"leftChild\":{\"id\":2,\"prediction\":[]},\"rightChild\":{\"id\":3,\"prediction\":[]}}},\n",
      "{\"id\":0,\"feature\":63,\"leftChild\":{\"id\":1,\"feature\":0,\"leftChild\":{\"id\":2,\"prediction\":[]}},\"rightChild\":{\"id\":3,\"prediction\":[]}},\n",
      "{\"id\":0,\"feature\":63,\"rightChild\":{\"id\":1,\"feature\":9,\"leftChild\":{\"id\":2,\"prediction\":[]},\"rightChild\":{\"id\":3,\"prediction\":[]}}},\n",
      "{\"id\":0,\"feature\":63,\"rightChild\":{\"id\":1,\"feature\":0,\"leftChild\":{\"id\":2,\"prediction\":[]},\"rightChild\":{\"id\":3,\"prediction\":[]}}},\n",
      "{\"id\":0,\"feature\":26,\"rightChild\":{\"id\":1,\"feature\":9,\"leftChild\":{\"id\":2,\"prediction\":[]},\"rightChild\":{\"id\":3,\"prediction\":[]}}},\n",
      "{\"id\":0,\"feature\":0,\"leftChild\":{\"id\":1,\"feature\":9,\"leftChild\":{\"id\":2,\"prediction\":[]},\"rightChild\":{\"id\":3,\"prediction\":[]}}},\n",
      "{\"id\":0,\"feature\":0,\"leftChild\":{\"id\":1,\"feature\":9,\"leftChild\":{\"id\":2,\"prediction\":[]}},\"rightChild\":{\"id\":3,\"prediction\":[]}},\n",
      "{\"id\":0,\"feature\":0,\"rightChild\":{\"id\":1,\"feature\":0,\"leftChild\":{\"id\":2,\"prediction\":[]},\"rightChild\":{\"id\":3,\"prediction\":[]}}},\n",
      "{\"id\":0,\"feature\":0,\"rightChild\":{\"id\":1,\"feature\":63,\"leftChild\":{\"id\":2,\"prediction\":[]},\"rightChild\":{\"id\":3,\"prediction\":[]}}},\n",
      "{\"id\":0,\"feature\":0,\"rightChild\":{\"id\":1,\"feature\":9,\"leftChild\":{\"id\":2,\"prediction\":[]},\"rightChild\":{\"id\":3,\"prediction\":[]}}},\n",
      "{\"id\":0,\"feature\":9,\"leftChild\":{\"id\":1,\"prediction\":[]},\"rightChild\":{\"id\":2,\"feature\":0,\"rightChild\":{\"id\":3,\"prediction\":[]}}},\n",
      "{\"id\":0,\"feature\":9,\"rightChild\":{\"id\":1,\"feature\":0,\"leftChild\":{\"id\":2,\"prediction\":[]},\"rightChild\":{\"id\":3,\"prediction\":[]}}},\n",
      "{\"id\":0,\"feature\":9,\"rightChild\":{\"id\":1,\"feature\":9,\"leftChild\":{\"id\":2,\"prediction\":[]},\"rightChild\":{\"id\":3,\"prediction\":[]}}}]\n"
     ]
    }
   ],
   "source": [
    "jsons = '[' + ',\\n'.join(map(cString2json, cStringList)) + ']'\n",
    "print(jsons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write a small script that traverses the random forests and finds all embeddings and outputs them somehow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"feature\": 61,\n",
      "        \"id\": 0,\n",
      "        \"leftChild\": {\n",
      "            \"feature\": 63,\n",
      "            \"id\": 1,\n",
      "            \"leftChild\": {\n",
      "                \"id\": 2,\n",
      "                \"prediction\": []\n",
      "            }\n",
      "        },\n",
      "        \"rightChild\": {\n",
      "            \"id\": 3,\n",
      "            \"prediction\": []\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"feature\": 63,\n",
      "        \"id\": 0,\n",
      "        \"leftChild\": {\n",
      "            \"feature\": 0,\n",
      "            \"id\": 1,\n",
      "            \"leftChild\": {\n",
      "                \"id\": 2,\n",
      "                \"prediction\": []\n",
      "            },\n",
      "            \"rightChild\": {\n",
      "                \"id\": 3,\n",
      "                \"prediction\": []\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"feature\": 63,\n",
      "        \"id\": 0,\n",
      "        \"leftChild\": {\n",
      "            \"feature\": 0,\n",
      "            \"id\": 1,\n",
      "            \"leftChild\": {\n",
      "                \"id\": 2,\n",
      "                \"prediction\": []\n",
      "            }\n",
      "        },\n",
      "        \"rightChild\": {\n",
      "            \"id\": 3,\n",
      "            \"prediction\": []\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"feature\": 63,\n",
      "        \"id\": 0,\n",
      "        \"rightChild\": {\n",
      "            \"feature\": 9,\n",
      "            \"id\": 1,\n",
      "            \"leftChild\": {\n",
      "                \"id\": 2,\n",
      "                \"prediction\": []\n",
      "            },\n",
      "            \"rightChild\": {\n",
      "                \"id\": 3,\n",
      "                \"prediction\": []\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"feature\": 63,\n",
      "        \"id\": 0,\n",
      "        \"rightChild\": {\n",
      "            \"feature\": 0,\n",
      "            \"id\": 1,\n",
      "            \"leftChild\": {\n",
      "                \"id\": 2,\n",
      "                \"prediction\": []\n",
      "            },\n",
      "            \"rightChild\": {\n",
      "                \"id\": 3,\n",
      "                \"prediction\": []\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"feature\": 26,\n",
      "        \"id\": 0,\n",
      "        \"rightChild\": {\n",
      "            \"feature\": 9,\n",
      "            \"id\": 1,\n",
      "            \"leftChild\": {\n",
      "                \"id\": 2,\n",
      "                \"prediction\": []\n",
      "            },\n",
      "            \"rightChild\": {\n",
      "                \"id\": 3,\n",
      "                \"prediction\": []\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"feature\": 0,\n",
      "        \"id\": 0,\n",
      "        \"leftChild\": {\n",
      "            \"feature\": 9,\n",
      "            \"id\": 1,\n",
      "            \"leftChild\": {\n",
      "                \"id\": 2,\n",
      "                \"prediction\": []\n",
      "            },\n",
      "            \"rightChild\": {\n",
      "                \"id\": 3,\n",
      "                \"prediction\": []\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"feature\": 0,\n",
      "        \"id\": 0,\n",
      "        \"leftChild\": {\n",
      "            \"feature\": 9,\n",
      "            \"id\": 1,\n",
      "            \"leftChild\": {\n",
      "                \"id\": 2,\n",
      "                \"prediction\": []\n",
      "            }\n",
      "        },\n",
      "        \"rightChild\": {\n",
      "            \"id\": 3,\n",
      "            \"prediction\": []\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"feature\": 0,\n",
      "        \"id\": 0,\n",
      "        \"rightChild\": {\n",
      "            \"feature\": 0,\n",
      "            \"id\": 1,\n",
      "            \"leftChild\": {\n",
      "                \"id\": 2,\n",
      "                \"prediction\": []\n",
      "            },\n",
      "            \"rightChild\": {\n",
      "                \"id\": 3,\n",
      "                \"prediction\": []\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"feature\": 0,\n",
      "        \"id\": 0,\n",
      "        \"rightChild\": {\n",
      "            \"feature\": 63,\n",
      "            \"id\": 1,\n",
      "            \"leftChild\": {\n",
      "                \"id\": 2,\n",
      "                \"prediction\": []\n",
      "            },\n",
      "            \"rightChild\": {\n",
      "                \"id\": 3,\n",
      "                \"prediction\": []\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"feature\": 0,\n",
      "        \"id\": 0,\n",
      "        \"rightChild\": {\n",
      "            \"feature\": 9,\n",
      "            \"id\": 1,\n",
      "            \"leftChild\": {\n",
      "                \"id\": 2,\n",
      "                \"prediction\": []\n",
      "            },\n",
      "            \"rightChild\": {\n",
      "                \"id\": 3,\n",
      "                \"prediction\": []\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"feature\": 9,\n",
      "        \"id\": 0,\n",
      "        \"leftChild\": {\n",
      "            \"id\": 1,\n",
      "            \"prediction\": []\n",
      "        },\n",
      "        \"rightChild\": {\n",
      "            \"feature\": 0,\n",
      "            \"id\": 2,\n",
      "            \"rightChild\": {\n",
      "                \"id\": 3,\n",
      "                \"prediction\": []\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"feature\": 9,\n",
      "        \"id\": 0,\n",
      "        \"rightChild\": {\n",
      "            \"feature\": 0,\n",
      "            \"id\": 1,\n",
      "            \"leftChild\": {\n",
      "                \"id\": 2,\n",
      "                \"prediction\": []\n",
      "            },\n",
      "            \"rightChild\": {\n",
      "                \"id\": 3,\n",
      "                \"prediction\": []\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"feature\": 9,\n",
      "        \"id\": 0,\n",
      "        \"rightChild\": {\n",
      "            \"feature\": 9,\n",
      "            \"id\": 1,\n",
      "            \"leftChild\": {\n",
      "                \"id\": 2,\n",
      "                \"prediction\": []\n",
      "            },\n",
      "            \"rightChild\": {\n",
      "                \"id\": 3,\n",
      "                \"prediction\": []\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "\n",
    "j = json.loads(jsons)\n",
    "print(json.dumps(j, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There must be a smarter way than the following. \n",
    "However, this is rather easy to implement:\n",
    "We iterate (recursively) over the transaction (decision) tree vertices $v$ and check whether there is a rooted subgraph isomorphism from pattern to the transaction mapping the root of pattern to $v$.\n",
    "This is decided by (again) recursion over pattern and transaction simultaneously, as long as it fits.\n",
    "\n",
    "We'll see whether this is fast enough for our case. Its something along $O(n * p)$ where $n$ and $p$ are the numbers of vertices of transactions and patterns, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printInfo(pattern, transaction, where):\n",
    "    print(where)\n",
    "    print('p: ' + str(pattern))\n",
    "    print('t: ' + str(transaction))\n",
    "\n",
    "\n",
    "def recSearch(pattern, transaction, mapping):\n",
    "    # check if we are in a leaf vertex in both pattern and transaction\n",
    "    if 'prediction' in pattern.keys() and 'prediction' in transaction.keys():\n",
    "        mapping[pattern['id']] = transaction['id']\n",
    "        return True\n",
    "    \n",
    "    # check if we are in a split vertex in both pattern and transaction\n",
    "    if 'feature' in pattern.keys() and 'feature' in transaction.keys():\n",
    "\n",
    "        # check if split features match\n",
    "        if pattern['feature'] == transaction['feature']:\n",
    "            \n",
    "            foundLeft = True\n",
    "            foundRight = True\n",
    "            if 'leftChild' in pattern.keys():\n",
    "                if 'leftChild' in transaction.keys():\n",
    "                    foundLeft = recSearch(pattern['leftChild'], transaction['leftChild'], mapping)    \n",
    "                else:\n",
    "                    foundLeft = False\n",
    "                \n",
    "            if 'rightChild' in pattern.keys():\n",
    "                if 'rightChild' in transaction.keys():\n",
    "                    foundRight = recSearch(pattern['rightChild'], transaction['rightChild'], mapping)\n",
    "                else:\n",
    "                    foundRight = False\n",
    "                \n",
    "            if foundLeft and foundRight:\n",
    "                mapping[pattern['id']] = transaction['id']\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "            \n",
    "    # if we are in the mixed case split vertex vs. leaf vertex then we cannot map the vertices on each other\n",
    "    return False\n",
    "\n",
    "\n",
    "def searchEmbedding(pattern, transaction):\n",
    "    '''For two given root vertices, check whether pattern is a rooted \n",
    "    subtree and return a mapping id->id if so, o/w None'''\n",
    "    \n",
    "    mapping = dict()\n",
    "    if recSearch(pattern, transaction, mapping):\n",
    "        return mapping\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def allEmbeddingsRec(pattern, transaction, result):\n",
    "    print('process transaction vertex id ' + str(transaction['id']))\n",
    "    if 'feature' in transaction.keys():\n",
    "        if 'leftChild' in transaction.keys():\n",
    "            allEmbeddingsRec(pattern, transaction['leftChild'], result)\n",
    "        if 'rightChild' in transaction.keys():\n",
    "            allEmbeddingsRec(pattern, transaction['rightChild'], result)\n",
    "    \n",
    "    result.append((transaction['id'], searchEmbedding(pattern, transaction)))\n",
    "    return result\n",
    "\n",
    "\n",
    "def allEmbeddings(pattern, transaction):\n",
    "    embeddingsAndNone = allEmbeddingsRec(pattern, transaction, list())\n",
    "    return embeddingsAndNone #list(filter(lambda x: x != None, embeddingsAndNone))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(2, None), (1, None), (3, None), (0, {2: 2, 1: 1, 3: 3, 0: 0})]\n",
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(2, None), (3, None), (1, None), (0, None)]\n",
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(2, None), (1, None), (3, None), (0, None)]\n",
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(2, None), (3, None), (1, None), (0, None)]\n",
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(2, None), (3, None), (1, None), (0, None)]\n",
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(2, None), (3, None), (1, None), (0, None)]\n",
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(2, None), (3, None), (1, None), (0, None)]\n",
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(2, None), (1, None), (3, None), (0, None)]\n",
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(2, None), (3, None), (1, None), (0, None)]\n",
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(2, None), (3, None), (1, None), (0, None)]\n",
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(2, None), (3, None), (1, None), (0, None)]\n",
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(1, None), (3, None), (2, None), (0, None)]\n",
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(2, None), (3, None), (1, None), (0, None)]\n",
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(2, None), (3, None), (1, None), (0, None)]\n"
     ]
    }
   ],
   "source": [
    "for transaction in j:\n",
    "    print(allEmbeddings(j[0], transaction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 0, 'feature': 61, 'leftChild': {'id': 1, 'feature': 63, 'leftChild': {'id': 2, 'prediction': []}}, 'rightChild': {'id': 3, 'prediction': []}}\n",
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(2, {1: 2}), (1, None), (3, {1: 3}), (0, None)]\n",
      "{'id': 0, 'feature': 63, 'leftChild': {'id': 1, 'feature': 0, 'leftChild': {'id': 2, 'prediction': []}, 'rightChild': {'id': 3, 'prediction': []}}}\n",
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(2, {1: 2}), (3, {1: 3}), (1, None), (0, None)]\n",
      "{'id': 0, 'feature': 63, 'leftChild': {'id': 1, 'feature': 0, 'leftChild': {'id': 2, 'prediction': []}}, 'rightChild': {'id': 3, 'prediction': []}}\n",
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(2, {1: 2}), (1, None), (3, {1: 3}), (0, None)]\n",
      "{'id': 0, 'feature': 63, 'rightChild': {'id': 1, 'feature': 9, 'leftChild': {'id': 2, 'prediction': []}, 'rightChild': {'id': 3, 'prediction': []}}}\n",
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(2, {1: 2}), (3, {1: 3}), (1, None), (0, None)]\n",
      "{'id': 0, 'feature': 63, 'rightChild': {'id': 1, 'feature': 0, 'leftChild': {'id': 2, 'prediction': []}, 'rightChild': {'id': 3, 'prediction': []}}}\n",
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(2, {1: 2}), (3, {1: 3}), (1, None), (0, None)]\n",
      "{'id': 0, 'feature': 26, 'rightChild': {'id': 1, 'feature': 9, 'leftChild': {'id': 2, 'prediction': []}, 'rightChild': {'id': 3, 'prediction': []}}}\n",
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(2, {1: 2}), (3, {1: 3}), (1, None), (0, None)]\n",
      "{'id': 0, 'feature': 0, 'leftChild': {'id': 1, 'feature': 9, 'leftChild': {'id': 2, 'prediction': []}, 'rightChild': {'id': 3, 'prediction': []}}}\n",
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(2, {1: 2}), (3, {1: 3}), (1, None), (0, None)]\n",
      "{'id': 0, 'feature': 0, 'leftChild': {'id': 1, 'feature': 9, 'leftChild': {'id': 2, 'prediction': []}}, 'rightChild': {'id': 3, 'prediction': []}}\n",
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(2, {1: 2}), (1, None), (3, {1: 3}), (0, None)]\n",
      "{'id': 0, 'feature': 0, 'rightChild': {'id': 1, 'feature': 0, 'leftChild': {'id': 2, 'prediction': []}, 'rightChild': {'id': 3, 'prediction': []}}}\n",
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(2, {1: 2}), (3, {1: 3}), (1, None), (0, None)]\n",
      "{'id': 0, 'feature': 0, 'rightChild': {'id': 1, 'feature': 63, 'leftChild': {'id': 2, 'prediction': []}, 'rightChild': {'id': 3, 'prediction': []}}}\n",
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(2, {1: 2}), (3, {1: 3}), (1, None), (0, None)]\n",
      "{'id': 0, 'feature': 0, 'rightChild': {'id': 1, 'feature': 9, 'leftChild': {'id': 2, 'prediction': []}, 'rightChild': {'id': 3, 'prediction': []}}}\n",
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(2, {1: 2}), (3, {1: 3}), (1, None), (0, None)]\n",
      "{'id': 0, 'feature': 9, 'leftChild': {'id': 1, 'prediction': []}, 'rightChild': {'id': 2, 'feature': 0, 'rightChild': {'id': 3, 'prediction': []}}}\n",
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(1, {1: 1}), (3, {1: 3}), (2, None), (0, None)]\n",
      "{'id': 0, 'feature': 9, 'rightChild': {'id': 1, 'feature': 0, 'leftChild': {'id': 2, 'prediction': []}, 'rightChild': {'id': 3, 'prediction': []}}}\n",
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(2, {1: 2}), (3, {1: 3}), (1, None), (0, None)]\n",
      "{'id': 0, 'feature': 9, 'rightChild': {'id': 1, 'feature': 9, 'leftChild': {'id': 2, 'prediction': []}, 'rightChild': {'id': 3, 'prediction': []}}}\n",
      "process transaction vertex id 0\n",
      "process transaction vertex id 1\n",
      "process transaction vertex id 2\n",
      "process transaction vertex id 3\n",
      "[(2, {1: 2}), (3, {1: 3}), (1, None), (0, None)]\n"
     ]
    }
   ],
   "source": [
    "leaf = json.loads('{\"id\": 1,\"prediction\": []}')\n",
    "for transaction in j:\n",
    "    print(transaction)\n",
    "    print(allEmbeddings(leaf, transaction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script, without Debug Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printInfo(pattern, transaction, where):\n",
    "    print(where)\n",
    "    print('p: ' + str(pattern))\n",
    "    print('t: ' + str(transaction))\n",
    "\n",
    "\n",
    "def recSearch(pattern, transaction, mapping):\n",
    "    # check if we are in a leaf vertex in both pattern and transaction\n",
    "    if 'prediction' in pattern.keys() and 'prediction' in transaction.keys():\n",
    "        mapping[pattern['id']] = transaction['id']\n",
    "        return True\n",
    "    \n",
    "    # check if we are in a split vertex in both pattern and transaction\n",
    "    if 'feature' in pattern.keys() and 'feature' in transaction.keys():\n",
    "\n",
    "        # check if split features match\n",
    "        if pattern['feature'] == transaction['feature']:\n",
    "            \n",
    "            foundLeft = True\n",
    "            foundRight = True\n",
    "            if 'leftChild' in pattern.keys():\n",
    "                if 'leftChild' in transaction.keys():\n",
    "                    foundLeft = recSearch(pattern['leftChild'], transaction['leftChild'], mapping)    \n",
    "                else:\n",
    "                    foundLeft = False\n",
    "                \n",
    "            if 'rightChild' in pattern.keys():\n",
    "                if 'rightChild' in transaction.keys():\n",
    "                    foundRight = recSearch(pattern['rightChild'], transaction['rightChild'], mapping)\n",
    "                else:\n",
    "                    foundRight = False\n",
    "                \n",
    "            if foundLeft and foundRight:\n",
    "                mapping[pattern['id']] = transaction['id']\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "            \n",
    "    # if we are in the mixed case split vertex vs. leaf vertex then we cannot map the vertices on each other\n",
    "    return False\n",
    "\n",
    "\n",
    "def searchEmbedding(pattern, transaction):\n",
    "    '''For two given root vertices, check whether pattern is a rooted \n",
    "    subtree and return a mapping id->id if so, o/w None'''\n",
    "    \n",
    "    mapping = dict()\n",
    "    if recSearch(pattern, transaction, mapping):\n",
    "        return mapping\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def allEmbeddingsRec(pattern, transaction, result):\n",
    "    if 'feature' in transaction.keys():\n",
    "        if 'leftChild' in transaction.keys():\n",
    "            allEmbeddingsRec(pattern, transaction['leftChild'], result)\n",
    "        if 'rightChild' in transaction.keys():\n",
    "            allEmbeddingsRec(pattern, transaction['rightChild'], result)\n",
    "    \n",
    "    result.append(searchEmbedding(pattern, transaction))\n",
    "    return result\n",
    "\n",
    "\n",
    "def allEmbeddings(pattern, transaction):\n",
    "    embeddingsAndNone = allEmbeddingsRec(pattern, transaction, list())\n",
    "    return list(filter(lambda x: x != None, embeddingsAndNone))\n",
    "\n",
    "\n",
    "\n",
    "# def main(file, out):\n",
    "#     f = open(file)\n",
    "#     j = json.load(f)\n",
    "#     f.close()\n",
    "\n",
    "#     graphCounter = 0\n",
    "#     for tree in j:\n",
    "#         vertexLabels, edges = parseTree(tree)\n",
    "#         transform2GraphDB(vertexLabels, edges, graphCounter, out)\n",
    "#         graphCounter += 1\n",
    "#     print('$')\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main(sys.argv[1], sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 0, 'feature': 61, 'leftChild': {'id': 1, 'feature': 63, 'leftChild': {'id': 2, 'prediction': []}}, 'rightChild': {'id': 3, 'prediction': []}}\n",
      "[{1: 2}, {1: 3}]\n",
      "{'id': 0, 'feature': 63, 'leftChild': {'id': 1, 'feature': 0, 'leftChild': {'id': 2, 'prediction': []}, 'rightChild': {'id': 3, 'prediction': []}}}\n",
      "[{1: 2}, {1: 3}]\n",
      "{'id': 0, 'feature': 63, 'leftChild': {'id': 1, 'feature': 0, 'leftChild': {'id': 2, 'prediction': []}}, 'rightChild': {'id': 3, 'prediction': []}}\n",
      "[{1: 2}, {1: 3}]\n",
      "{'id': 0, 'feature': 63, 'rightChild': {'id': 1, 'feature': 9, 'leftChild': {'id': 2, 'prediction': []}, 'rightChild': {'id': 3, 'prediction': []}}}\n",
      "[{1: 2}, {1: 3}]\n",
      "{'id': 0, 'feature': 63, 'rightChild': {'id': 1, 'feature': 0, 'leftChild': {'id': 2, 'prediction': []}, 'rightChild': {'id': 3, 'prediction': []}}}\n",
      "[{1: 2}, {1: 3}]\n",
      "{'id': 0, 'feature': 26, 'rightChild': {'id': 1, 'feature': 9, 'leftChild': {'id': 2, 'prediction': []}, 'rightChild': {'id': 3, 'prediction': []}}}\n",
      "[{1: 2}, {1: 3}]\n",
      "{'id': 0, 'feature': 0, 'leftChild': {'id': 1, 'feature': 9, 'leftChild': {'id': 2, 'prediction': []}, 'rightChild': {'id': 3, 'prediction': []}}}\n",
      "[{1: 2}, {1: 3}]\n",
      "{'id': 0, 'feature': 0, 'leftChild': {'id': 1, 'feature': 9, 'leftChild': {'id': 2, 'prediction': []}}, 'rightChild': {'id': 3, 'prediction': []}}\n",
      "[{1: 2}, {1: 3}]\n",
      "{'id': 0, 'feature': 0, 'rightChild': {'id': 1, 'feature': 0, 'leftChild': {'id': 2, 'prediction': []}, 'rightChild': {'id': 3, 'prediction': []}}}\n",
      "[{1: 2}, {1: 3}]\n",
      "{'id': 0, 'feature': 0, 'rightChild': {'id': 1, 'feature': 63, 'leftChild': {'id': 2, 'prediction': []}, 'rightChild': {'id': 3, 'prediction': []}}}\n",
      "[{1: 2}, {1: 3}]\n",
      "{'id': 0, 'feature': 0, 'rightChild': {'id': 1, 'feature': 9, 'leftChild': {'id': 2, 'prediction': []}, 'rightChild': {'id': 3, 'prediction': []}}}\n",
      "[{1: 2}, {1: 3}]\n",
      "{'id': 0, 'feature': 9, 'leftChild': {'id': 1, 'prediction': []}, 'rightChild': {'id': 2, 'feature': 0, 'rightChild': {'id': 3, 'prediction': []}}}\n",
      "[{1: 1}, {1: 3}]\n",
      "{'id': 0, 'feature': 9, 'rightChild': {'id': 1, 'feature': 0, 'leftChild': {'id': 2, 'prediction': []}, 'rightChild': {'id': 3, 'prediction': []}}}\n",
      "[{1: 2}, {1: 3}]\n",
      "{'id': 0, 'feature': 9, 'rightChild': {'id': 1, 'feature': 9, 'leftChild': {'id': 2, 'prediction': []}, 'rightChild': {'id': 3, 'prediction': []}}}\n",
      "[{1: 2}, {1: 3}]\n"
     ]
    }
   ],
   "source": [
    "leaf = json.loads('{\"id\": 1,\"prediction\": []}')\n",
    "for transaction in j:\n",
    "    print(transaction)\n",
    "    print(allEmbeddings(leaf, transaction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 17, 10, 18, 15, 12, 20, 10, 14, 12, 14, 13, 16, 23]\n"
     ]
    }
   ],
   "source": [
    "filename = 'forests/adult/text/RF_10.json'\n",
    "f = open(filename, 'r')\n",
    "transactions = json.load(f)\n",
    "f.close()\n",
    "\n",
    "patterns = j\n",
    "\n",
    "embeddingCounts = list()\n",
    "\n",
    "for pattern in patterns:\n",
    "    counts = 0\n",
    "    for transaction in transactions:\n",
    "        mappings = allEmbeddings(pattern, transaction)\n",
    "        counts += len(mappings)\n",
    "    embeddingCounts.append(counts)\n",
    "print(embeddingCounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 14, 10, 15, 11, 11, 15, 10, 10, 10, 11, 10, 10, 13]\n"
     ]
    }
   ],
   "source": [
    "filename = 'forests/rootedFrequentTrees/adult/WithLeafEdges/RF_10_t10.patterns'\n",
    "f = open(filename)\n",
    "\n",
    "# gives us the patterns of the selected size\n",
    "frequentPatterns = filter(lambda line: line.count('(') == patternSize, f)\n",
    "\n",
    "# gives us only the canonical strings of the patterns\n",
    "patternCountsFromAlg = list(map(lambda fp: int(fp.split('\\t')[0]), frequentPatterns))\n",
    "\n",
    "print(patternCountsFromAlg)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We have now the tools to transform the data and compute all embeddings of frequent patterns explicitly. \n",
    "This will be soon put in a nice script that is usable from the command line.\n",
    "\n",
    "As a fist quick glance, it seems that the patterns that were identified as frequent mostly have only one embedding per random decision tree. \n",
    "But this needs to be investigated more closely."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
