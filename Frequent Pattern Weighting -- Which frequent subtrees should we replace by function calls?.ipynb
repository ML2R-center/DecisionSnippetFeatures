{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now computed, for all random forests and all frequency thresholds, \n",
    "\n",
    "- the frequent patterns ( Initial Rooted Frequent Subtree Mining (without embedding computation).ipynb )\n",
    "- all embeddings for each frequent pattern up to size 6 ( Find All Occurrences of All Frequent Patterns of Size up to 6.ipynb )\n",
    "\n",
    "Thus, we have lots of files that store the random forests and some embedding information of the patterns and files that contain pattern info.\n",
    "\n",
    "By loading a pair of files, e.g.,\n",
    "\n",
    "    forests/rootedFrequentTrees/adult/WithLeafEdges/leq6/ET_10_t16_allEmbeddings.json\n",
    "    forests/rootedFrequentTrees/adult/WithLeafEdges/leq6/ET_10_t16.json\n",
    "    \n",
    "We have all the information necessary to see how much it helps us to replace all subtrees in a RF corresponding to a pattern with a function.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def embeddingStatsRec(transaction, weightfunction, counter):\n",
    "    if 'feature' in transaction.keys():\n",
    "        if 'leftChild' in transaction.keys():\n",
    "            embeddingStatsRec(transaction['leftChild'], weightfunction, counter)\n",
    "        if 'rightChild' in transaction.keys():\n",
    "            embeddingStatsRec(transaction['rightChild'], weightfunction, counter)\n",
    "    \n",
    "    for pattern in transaction['patterns']:\n",
    "        counter[pattern[0]] += weightfunction(pattern, transaction)\n",
    "\n",
    "    \n",
    "\n",
    "def embeddingStats(transactions, weightfunction):\n",
    "    '''Apply weightfunction to all embeddings of each pattern in each transaction and return, for each pattern,\n",
    "    the sum of gains.\n",
    "    \n",
    "    Due to implementation, weightfunction must \n",
    "    - take a pattern and a transaction vertex (the root of the embedding being currently weighted) as input and \n",
    "    - output an int.\n",
    "    '''\n",
    "    cnt = Counter()\n",
    "    for transaction in transactions:\n",
    "        embeddingStatsRec(transaction, weightfunction, cnt)\n",
    "    return cnt\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some patterns and a random forest with all their embeddings\n",
    "\n",
    "embeddingFile = open('/home/pascal/Documents/Uni_synced/random_forests/forests/rootedFrequentTrees/adult/WithLeafEdges/leq6/ET_10_t16_allEmbeddings.json')\n",
    "patternFile = open('/home/pascal/Documents/Uni_synced/random_forests/forests/rootedFrequentTrees/adult/WithLeafEdges/leq6/ET_10_t16.json')\n",
    "\n",
    "embeddingInfo = json.load(embeddingFile)\n",
    "patterns = json.load(patternFile)\n",
    "\n",
    "embeddingFile.close()\n",
    "patternFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the list of patterns to a dict for easy access\n",
    "\n",
    "patternDict = { pattern['patternid'] : pattern['pattern'] for pattern in patterns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 8177),\n",
       " (3, 566),\n",
       " (1, 548),\n",
       " (52, 521),\n",
       " (22, 508),\n",
       " (155, 489),\n",
       " (75, 373),\n",
       " (6, 350),\n",
       " (157, 339),\n",
       " (156, 332)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the patterns that occur in at least 16 of the trees in ET_10 with most embeddings in ET_10\n",
    "# that is, each embedding counts for 1\n",
    "\n",
    "embeddingCounts = embeddingStats(embeddingInfo, weightfunction=lambda p,t : 1)\n",
    "embeddingCounts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0, 'prediction': []}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can access the corresponding patterns like this\n",
    "\n",
    "patternDict[10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, (and as was to be expected) the pattern that occurs most frequently is rather small. \n",
    "I.e., it consists of a single vertex.\n",
    "\n",
    "This of course is not a useful pattern to be replaced by a function call.\n",
    "\n",
    "Let's try a different weight function, that tells us, how much vertices we could save in the RF by contracting each embedding of a pattern into a single vertex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(193, 552),\n",
       " (160, 532),\n",
       " (155, 489),\n",
       " (174, 450),\n",
       " (161, 434),\n",
       " (75, 373),\n",
       " (157, 339),\n",
       " (156, 332),\n",
       " (73, 332),\n",
       " (120, 311)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddingSavings = embeddingStats(embeddingInfo, weightfunction=lambda p,t : len(p[1]) - 1)\n",
    "embeddingSavings.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"193: w=552, p={'id': 0, 'feature': 9, 'leftChild': {'id': 1, 'prediction': []}, 'rightChild': {'id': 2, 'prediction': []}}\",\n",
       " \"160: w=532, p={'id': 0, 'feature': 0, 'leftChild': {'id': 1, 'prediction': []}, 'rightChild': {'id': 2, 'prediction': []}}\",\n",
       " \"155: w=489, p={'id': 0, 'feature': 61, 'rightChild': {'id': 1, 'prediction': []}}\",\n",
       " \"174: w=450, p={'id': 0, 'feature': 63, 'leftChild': {'id': 1, 'prediction': []}, 'rightChild': {'id': 2, 'prediction': []}}\",\n",
       " \"161: w=434, p={'id': 0, 'feature': 61, 'leftChild': {'id': 1, 'prediction': []}, 'rightChild': {'id': 2, 'prediction': []}}\",\n",
       " \"75: w=373, p={'id': 0, 'feature': 9, 'rightChild': {'id': 1, 'prediction': []}}\",\n",
       " \"157: w=339, p={'id': 0, 'feature': 0, 'rightChild': {'id': 1, 'prediction': []}}\",\n",
       " \"156: w=332, p={'id': 0, 'feature': 0, 'leftChild': {'id': 1, 'prediction': []}}\",\n",
       " \"73: w=332, p={'id': 0, 'feature': 9, 'leftChild': {'id': 1, 'prediction': []}}\",\n",
       " \"120: w=311, p={'id': 0, 'feature': 63, 'leftChild': {'id': 1, 'prediction': []}}\"]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: '{0}: w={1}, p={2}'.format(x[0], x[1], patternDict[x[0]]), embeddingSavings.most_common(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature': 9,\n",
       " 'id': 0,\n",
       " 'leftChild': {'id': 1, 'prediction': []},\n",
       " 'rightChild': {'id': 2, 'prediction': []}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patternDict[193]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "\n",
    "- What are useful weighting functions for our actual scenario?\n",
    "- How do we deal with overlaps of the embeddings?\n",
    "  - Is it more useful to process patterns that are higher up in the DT first? (I guess)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
